"""
This module contains the complete pipeline for training and evaluating
Hidden Markov Models (HMMs) for spoken digit recognition (Steps 10-13).
It encapsulates model creation, hyperparameter tuning, and evaluation logic.
"""

import time
from typing import Dict, List, Tuple, Any

import numpy as np
import pandas as pd
from pomegranate.distributions import Normal
from pomegranate.gmm import GeneralMixtureModel
from pomegranate.hmm import DenseHMM
from sklearn.metrics import accuracy_score


def _create_hmm_for_digit(
    X: List[np.ndarray], n_states: int, n_mixtures: int, covariance_type: str
) -> DenseHMM:
    """
    Creates, configures, and trains a single left-to-right HMM for one digit.

    This function builds a GMM-HMM with a strict left-to-right topology. It is
    critical that all NumPy arrays passed to pomegranate components (data for fitting,
    transition matrices, etc.) share the same floating-point data type to avoid errors.
    Here, we consistently use np.float32, as it was proven to work in the original notebook.

    Args:
        X (List[np.ndarray]): The list of training feature sequences for a single digit.
        n_states (int): The number of states for the HMM.
        n_mixtures (int): The number of Gaussian components for the GMMs.
        covariance_type (str): The covariance type for the GMMs ('diag' or 'full').

    Returns:
        DenseHMM: The trained HMM model for the specified digit.
    """
    # --- 1. Initialize Emission Probability Distributions (GMMs) ---
    # The GMM for each state is trained on all frames from all training samples of the current digit.
    # This provides a robust estimate of the feature distribution for each state.
    # Pomegranate is sensitive to data types, so we explicitly cast to np.float32.
    all_frames = np.concatenate(X).astype(np.float32)
    distributions = []
    for _ in range(n_states):
        # Each GMM is a mixture of several base Normal (Gaussian) distributions.
        base_distributions = [
            Normal(covariance_type=covariance_type) for _ in range(n_mixtures)
        ]
        # The GeneralMixtureModel is fitted using the Expectation-Maximization (EM) algorithm.
        gmm = GeneralMixtureModel(base_distributions, verbose=False).fit(all_frames)
        distributions.append(gmm)

    # --- 2. Define the Transition Matrix ---
    # A left-to-right topology is used, which is standard for modeling temporal sequences
    # like speech, where the process moves forward through states.
    # The matrix must also be of the same dtype, np.float32.
    transitions = np.zeros((n_states, n_states), dtype=np.float32)
    for i in range(n_states - 1):
        transitions[i, i] = 0.5      # Probability of staying in the same state (self-transition).
        transitions[i, i + 1] = 0.5  # Probability of moving to the next sequential state.
    # The final state is an absorbing state; the model can only remain in it.
    transitions[n_states - 1, n_states - 1] = 1.0

    # --- 3. Define Start and End Probabilities ---
    # This enforces that every sequence must begin in the first state and end in the last.
    # These vectors must also be of type np.float32.
    starts = np.zeros(n_states, dtype=np.float32)
    starts[0] = 1.0
    ends = np.zeros(n_states, dtype=np.float32)
    ends[n_states - 1] = 1.0

    # --- 4. Create and Train the HMM ---
    # The HMM is trained using the Baum-Welch algorithm, which is a specialized version of EM for HMMs.
    # The input data for fitting must be a list of np.float32 arrays.
    model_data = [x.astype(np.float32) for x in X]
    
    model = DenseHMM(
        distributions=distributions,
        edges=transitions,
        starts=starts,
        ends=ends,
        max_iter=15, # Number of EM iterations for the Baum-Welch algorithm.
        verbose=False,
    ).fit(model_data)

    return model


def evaluate_hmm_models(
    hmm_models: Dict[int, DenseHMM], data_dic: Dict, all_labels: List[int]
) -> Tuple[List[int], List[int]]:
    """
    Evaluates a set of trained HMMs on a given dataset (validation or test).

    For each sequence, this function calculates the log-likelihood that it was
    generated by each digit-specific HMM and selects the digit with the
    highest likelihood as the prediction.
    """
    predicted_labels, true_labels = [], []

    # Iterate through each digit's data in the dataset.
    for true_digit in all_labels:
        sequences = data_dic[true_digit]["features"]
        
        for seq in sequences:
            log_likelihoods = {}
            # The model's log_probability method expects a batch (a list of sequences).
            # We also ensure the sequence is of the correct dtype, np.float32.
            sequence_batch = [seq.astype(np.float32)]

            # Calculate the log probability of the sequence under each digit's HMM.
            for model_digit, hmm in hmm_models.items():
                logp = hmm.log_probability(sequence_batch)
                # Handle the case where the sequence is impossible under a model (-inf probability).
                log_likelihoods[model_digit] = logp if not np.isneginf(logp) else -1e18

            # The predicted digit corresponds to the model that yielded the highest log-likelihood.
            predicted_digit = max(log_likelihoods, key=log_likelihoods.get)
            
            predicted_labels.append(predicted_digit)
            true_labels.append(true_digit)

    return predicted_labels, true_labels


def run_hmm_hyperparameter_tuning(
    train_dic: Dict, val_dic: Dict, all_labels: List[int]
) -> Tuple[Dict[int, DenseHMM], Dict[str, Any], pd.DataFrame]:
    """
    Performs a grid search over HMM hyperparameters to find the best configuration.

    This function systematically trains and evaluates HMMs with different numbers
    of states and GMM mixtures, using the validation set to select the best model.
    """
    # --- Grid Definition ---
    # Define the range of hyperparameters to be tested.
    state_range = range(2, 5)        # Test with 2, 3, and 4 states.
    mixture_range = range(2, 6)      # Test with 2, 3, 4, and 5 GMM components.
    covariance_types = ["diag", "full"] # Test both diagonal and full covariance matrices.

    # --- Tracking Variables ---
    # Initialize variables to keep track of the best performing model found so far.
    best_accuracy = -1.0
    best_params = {}
    best_hmm_models = None
    results_list = []

    print("\n" + "=" * 80)
    print("STARTING HMM HYPERPARAMETER TUNING")
    print("=" * 80)
    total_start_time = time.time()

    # --- Grid Search Loop ---
    # Iterate over all combinations of the defined hyperparameters.
    for cov_type in covariance_types:
        for states in state_range:
            for mixtures in mixture_range:
                params = {"n_states": states, "n_mixtures": mixtures, "covariance_type": cov_type}
                print(f"\n--- Testing config: {params} ---")
                start_time = time.time()

                try:
                    # 1. Train a set of 10 HMMs (one per digit) for the current configuration.
                    current_hmms = {}
                    for digit in all_labels:
                        X_digit = train_dic[digit]["features"]
                        current_hmms[digit] = _create_hmm_for_digit(X_digit, **params)
                    
                    # 2. Evaluate the trained models on the validation set.
                    pred_val, true_val = evaluate_hmm_models(current_hmms, val_dic, all_labels)
                    accuracy = accuracy_score(true_val, pred_val)

                except Exception as e:
                    # Catch potential numerical errors during pomegranate's fitting process.
                    print(f"    ERROR during training/evaluation: {e}")
                    accuracy = 0.0

                duration = time.time() - start_time
                print(f"  Validation Accuracy: {accuracy:.4f} (took {duration:.2f}s)")
                
                # Store the results of this run for the final summary table.
                result_entry = params.copy()
                result_entry['accuracy'] = accuracy
                results_list.append(result_entry)

                # 3. If this configuration yielded the best accuracy so far, update the best model.
                if accuracy > best_accuracy:
                    best_accuracy = accuracy
                    best_params = params.copy()
                    best_hmm_models = current_hmms
                    print(f"  >>> New Best Model Found! <<<")

    total_duration = time.time() - total_start_time
    print("\n" + "=" * 80)
    print(f"Hyperparameter Tuning Finished in {total_duration:.2f}s")
    if best_hmm_models:
        print(f"Best Validation Accuracy: {best_accuracy:.4f}")
        print(f"Best Parameters: {best_params}")
    else:
        print("WARNING: No model was successfully trained.")
    print("=" * 80)
    
    # Return the best model found, its parameters, and a DataFrame with all results.
    return best_hmm_models, best_params, pd.DataFrame(results_list)